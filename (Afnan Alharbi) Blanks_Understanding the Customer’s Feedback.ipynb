{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q24hSxA4tA6n"
   },
   "source": [
    "# Text classification: Understanding the Customer's Feedback\n",
    "\n",
    "---\n",
    "\n",
    "Text classification is one of the important tasks of text mining\n",
    "\n",
    "![alt text](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1535125878/NLTK3_zwbdgg.png)\n",
    "\n",
    "In this notebook, we will perform Sentiment Analysis on IMDB movies reviews. Sentiment Analysis is the art of extracting people's opinion from digital text. We will use a regression model from Scikit-Learn able to predict the sentiment given a movie review.\n",
    "\n",
    "We will use [the IMDB movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/), which consists of 50,000 movies review (50% are positive, 50% are negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0O1jA8byt4bV"
   },
   "source": [
    "The libraries needed in this exercise are:\n",
    "* [Numpy](http://www.numpy.org/) — a package for scientific computing.\n",
    "* [Pandas](https://pandas.pydata.org/) — a library providing high-performance, easy-to-use data structures and data analysis tools for the Python\n",
    "* [Matplotlib](https://matplotlib.org/) — a package for plotting & visualizations.\n",
    "* [scikit-learn](http://scikit-learn.org/stable/index.html) — a tool for data mining and data analysis.\n",
    "* [NLTK](http://www.nltk.org/) — a platform to work with natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "844CS6rf57X7"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAt6rj955meo"
   },
   "source": [
    "### Importing the libraries and necessary dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RRN4WqkltlB5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afnan\\anaconda3\\A\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Afnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Afnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "# download Punkt Sentence Tokenizer\n",
    "nltk.download('punkt')\n",
    "# download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7duM74C95rhN"
   },
   "source": [
    "### Loading the dataset in our directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "c48UYWDcg3hR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-11-16 07:12:01--  https://raw.githubusercontent.com/javaidnabi31/Word-Embeddding-Sentiment-Classification/master/movie_data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 65862309 (63M) [text/plain]\n",
      "Saving to: 'movie_data.csv'\n",
      "\n",
      "
      " 37350K .......... .......... .......... .......... .......... 58% 1.42M 17s\n",
      " 37400K .......... .......... .......... .......... .......... 58% 1.32M 17s\n",
      " 37450K .......... .......... .......... .......... .......... 58% 1.64M 17s\n",
      " 37500K .......... .......... .......... .......... .......... 58% 6.66M 17s\n",
      " 37550K .......... .......... .......... .......... .......... 58% 2.02M 17s\n",
      " 37600K .......... .......... .......... .......... .......... 58%  774K 17s\n",
      
      " 49400K .......... .......... .......... .......... .......... 76% 1.76M 9s\n",
      " 49450K .......... .......... .......... .......... .......... 76% 2.89M 9s\n",
      " 49500K .......... .......... .......... .......... .......... 77% 1.45M 9s\n",
      " 49550K .......... .......... .......... .......... .......... 77% 1.63M 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49600K .......... .......... .......... .......... .......... 77%  378K 9s\n",
      " 49650K .......... .......... .......... .......... .......... 77% 14.9M 9s\n",
      
      " 55700K .......... .......... .......... .......... .......... 86% 3.36M 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55750K .......... .......... .......... .......... .......... 86% 11.8M 5s\n",
      " 55800K .......... .......... .......... .......... .......... 86% 26.2M 5s\n",
      " 55850K .......... .......... .......... .......... .......... 86% 3.24M 5s\n",

      " 63850K .......... .......... .......... .......... .......... 99% 1.58M 0s\n",
      " 63900K .......... .......... .......... .......... .......... 99% 7.13M 0s\n",
      " 63950K .......... .......... .......... .......... .......... 99% 2.52M 0s\n",
      " 64000K .......... .......... .......... .......... .......... 99% 5.74M 0s\n",
      " 64050K .......... .......... .......... .......... .......... 99% 6.54M 0s\n",
      " 64100K .......... .......... .......... .......... .......... 99% 1.59M 0s\n",
      " 64150K .......... .......... .......... .......... .......... 99% 6.64M 0s\n",
      " 64200K .......... .......... .......... .......... .......... 99%  501K 0s\n",
      " 64250K .......... .......... .......... .......... .......... 99% 50.2M 0s\n",
      " 64300K .......... ........                                   100%  101M=36s\n",
      "\n",
      "2023-11-16 07:12:38 (1.74 MB/s) - 'movie_data.csv' saved [65862309/65862309]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download IMDB dataset\n",
    "!wget \"https://raw.githubusercontent.com/javaidnabi31/Word-Embeddding-Sentiment-Classification/master/movie_data.csv\" -O \"movie_data.csv\"\n",
    "\n",
    "# list files in current directory\n",
    "!ls -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77spW4xt5y4R"
   },
   "source": [
    "### Reading the dataset file and getting info on it\n",
    "**Question 1:** Use pandas to read the csv file and display the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R0A5QhDlteWj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I went and saw this movie last night after bei...          1\n",
       "1  Actor turned director Bill Paxton follows up h...          1\n",
       "2  As a recreational golfer with some knowledge o...          1\n",
       "3  I saw this film in a sneak preview, and it is ...          1\n",
       "4  Bill Paxton has taken the true story of the 19...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to IMDB dataseet\n",
    "dataset_path = 'movie_data.csv'\n",
    "\n",
    "# read file (dataset) into our program using pandas\n",
    "data = pd.read_csv('movie_data.csv')\n",
    "\n",
    "# display first 5 rows\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8oHmgm-6qK2"
   },
   "source": [
    "Getting info on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uQVx6AhqhAiB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPbcG_8k54JZ"
   },
   "source": [
    "A balanced dataset in sentiment analysis is a dataset which holds an equal amount of positive sentiment data and negative sentiment data, meaning 50% of the data is positive and 50% is negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgvEJ3BSK_7e"
   },
   "source": [
    "**Question 2:** Check if dataset is balanced (number of positive sentiment = number of negative sentiment) by plotting the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q12nMYY5vPhn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset is balanced (number of positive sentiment = number of negative sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4uAuueIwKkS"
   },
   "source": [
    "## Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qCxs0pSovUOa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this movie from beginning to end.I am a musician and i let drugs get in the way of my some of the things i used to love(skateboarding,drawing) but my friends were always there for me.Music was like my rehab,life support,and my drug.It changed my life.I can totally relate to this movie and i wish there was more i could say.This movie left me speechless to be honest.I just saw it on the Ifc channel.I usually hate having satellite but this was a perk of having satellite.The ifc channel shows some really great movies and without it I never would have found this movie.Im not a big fan of the international films because i find that a lot of the don't do a very good job on translating lines.I mean the obvious language barrier leaves you to just believe thats what they are saying but its not that big of a deal i guess.I almost never got to see this AMAZING movie.Good thing i stayed up for it instead of going to bed..well earlier than usual.lol.I hope you all enjoy the hell of this movie and Love this movie just as much as i did.I wish i could type this all in caps but its again the rules i guess thats shouting but it would really show my excitement for the film.I Give It Three Thumbs Way Up!<br /><br />This Movie Blew ME AWAY!\n"
     ]
    }
   ],
   "source": [
    "print(data.review[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAvczEBgxUWl"
   },
   "source": [
    "**Question 3:** Let's define a function that would clean each movie review (sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eKKIsHqZwRJR"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# define cleaning function\n",
    "def clean_review(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z]', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed = [stemmer.stem(word) for word in tokens]\n",
    "    text = ' '.join(stemmed)\n",
    "    text = ' '.join([word for word in text.split() if word not in english_stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NIqPBfK67Zc"
   },
   "source": [
    "**Question 4 :** Try it out on an instance of the dataset then on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "W4Bn3r1wzvwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mOriginal review: \u001b[39mI went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
      "\u001b[32mCleaned review: \u001b[39mwent saw thi movi last night coax friend mine admit wa reluct see becaus knew ashton kutcher wa onli abl comedi wa wrong kutcher play charact jake fischer veri well kevin costner play ben randal profession sign good movi toy emot thi one exactli entir theater wa sold wa overcom laughter dure first half movi move tear dure second half exit theater onli saw mani women tear mani full grown men well tri desper let anyon see cri thi movi wa great suggest go see befor judg\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore\n",
    "\n",
    "instance = data.iloc[0]\n",
    "review = instance['review']\n",
    "cleaned_review = clean_review(review)\n",
    "\n",
    "print(Fore.RED + 'Original review:', end=' ')\n",
    "print(Fore.RESET + review)\n",
    "print(Fore.GREEN + 'Cleaned review:', end=' ')\n",
    "print(Fore.RESET + cleaned_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24Ycze9C6_yb"
   },
   "source": [
    "And now clean the entire dataset reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6kHxWkPTz5eA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "      <td>went saw thi movi last night coax friend mine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "      <td>actor turn director bill paxton follow hi prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "      <td>recreat golfer knowledg sport histori wa pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>saw thi film sneak preview delight cinematogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "      <td>bill paxton ha taken true stori us golf open m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  I went and saw this movie last night after bei...          1   \n",
       "1  Actor turned director Bill Paxton follows up h...          1   \n",
       "2  As a recreational golfer with some knowledge o...          1   \n",
       "3  I saw this film in a sneak preview, and it is ...          1   \n",
       "4  Bill Paxton has taken the true story of the 19...          1   \n",
       "\n",
       "                                        clean_review  \n",
       "0  went saw thi movi last night coax friend mine ...  \n",
       "1  actor turn director bill paxton follow hi prom...  \n",
       "2  recreat golfer knowledg sport histori wa pleas...  \n",
       "3  saw thi film sneak preview delight cinematogra...  \n",
       "4  bill paxton ha taken true stori us golf open m...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply to all dataset\n",
    "data['clean_review'] = data['review'].apply(clean_review)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkVqSSzu2Ax8"
   },
   "source": [
    "## Split dataset for training and testing\n",
    "We will split our data into two subsets: a 50% subset will be used for training the model for prediction and the remaining 50% will be used for evaluating or testing its performance. The random state ensures reproducibility of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfMQ4DP0LahH"
   },
   "source": [
    "**Question 5:** Split your data to get x_train, x_test, y_train and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QPHlwVS71brN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['clean_review']\n",
    "y = data['sentiment']\n",
    "\n",
    "# Split data into 50% training & 50% test\n",
    "# Use a random state of 42 for example to ensure having the same split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz23g0nD2nhN"
   },
   "source": [
    "## Feature extraction with Bag of Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGHs66FILldh"
   },
   "source": [
    "**Question 6:**  In this section, apply the Bag of Words method to learn the vocabulary of your text and with it transform your training input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0_B0vrn-2sON"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000) (25000,)\n",
      "(25000, 10000) (25000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# define a CountVectorizer (with binary=True and max_features=10000)\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True, max_features=10000)\n",
    "\n",
    "# learn the vocabulary of all tokens in our training dataset\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# transform x_train to bag of words\n",
    "X_train_bow = vectorizer.transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_bow.shape, y_train.shape)\n",
    "print(X_test_bow.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtLaJfuw4060"
   },
   "source": [
    "## Classification\n",
    "\n",
    "**Question 7:** Your data is ready for classification. For this task use [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9mS51YGO4hfv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afnan\\anaconda3\\A\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define the LogisticRegression classifier\n",
    "model = LogisticRegression()\n",
    "# train the classifier on the training data\n",
    "model.fit(X_train_bow, y_train)\n",
    "\n",
    "# get the mean accuracy on the training data\n",
    "acc_train = model.score(X_train_bow, y_train)\n",
    "\n",
    "print('Training Accuracy:', acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Csw7GEm76E5"
   },
   "source": [
    "**Question 8:**  Evaluating the performance of your model through its accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "sBJnyoqO5NyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.86628\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with test data\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "acc_test = model.score(X_test_bow, y_test)\n",
    "\n",
    "print('Test Accuracy:', acc_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yh5927-d6Gq4"
   },
   "source": [
    "## Bonus: Let's use the model to predict!\n",
    "To do so, let's create a predict function which takes as argument your model and the bag of words vectorizer together with a review on which it would predict the sentiment. This review should be cleaned with the `clean_review` function we built, transformed by bag of words and then used for prediction with `model.predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "u6kxkZ5m55Ii"
   },
   "outputs": [],
   "source": [
    "# define predict function\n",
    "def predict(model, vectorizer, cleaned_review):\n",
    "    review_bow = vectorizer.transform([cleaned_review])\n",
    "    prediction = model.predict(review_bow)\n",
    "    \n",
    "    return prediction[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VrNunL18l4a"
   },
   "source": [
    "And let's try it out on an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "8z6WCl916flD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = 'The movie was great!'\n",
    "predict(model, vectorizer, review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the sentiment is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1vcR5u_wa0YXm4HoXDmnJcMVQyA6rl8Ex",
     "timestamp": 1690961435666
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
